{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks (CNNs): Complete Guide\n",
    "\n",
    "This notebook provides comprehensive coverage of CNNs from basic concepts to advanced architectures.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Understanding Convolutions](#convolution)\n",
    "3. [Building Basic CNN](#basic-cnn)\n",
    "4. [Classic Architectures](#architectures)\n",
    "5. [Transfer Learning](#transfer)\n",
    "6. [Visualization](#visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Understanding Convolutions <a name=\"convolution\"></a>\n",
    "\n",
    "Let's visualize how convolution operations work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_conv2d(input_img, kernel):\n",
    "    \"\"\"Manual implementation of 2D convolution for educational purposes\"\"\"\n",
    "    kh, kw = kernel.shape\n",
    "    ih, iw = input_img.shape\n",
    "    \n",
    "    # Output dimensions\n",
    "    oh = ih - kh + 1\n",
    "    ow = iw - kw + 1\n",
    "    \n",
    "    output = np.zeros((oh, ow))\n",
    "    \n",
    "    for i in range(oh):\n",
    "        for j in range(ow):\n",
    "            output[i, j] = np.sum(input_img[i:i+kh, j:j+kw] * kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Create a simple image and various kernels\n",
    "image = np.random.randn(10, 10)\n",
    "\n",
    "# Edge detection kernels\n",
    "sobel_x = np.array([[-1, 0, 1],\n",
    "                     [-2, 0, 2],\n",
    "                     [-1, 0, 1]])\n",
    "\n",
    "sobel_y = np.array([[-1, -2, -1],\n",
    "                     [ 0,  0,  0],\n",
    "                     [ 1,  2,  1]])\n",
    "\n",
    "# Apply convolutions\n",
    "edge_x = manual_conv2d(image, sobel_x)\n",
    "edge_y = manual_conv2d(image, sobel_y)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "axes[0].imshow(image, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[1].imshow(edge_x, cmap='gray')\n",
    "axes[1].set_title('Sobel X (Vertical Edges)')\n",
    "axes[2].imshow(edge_y, cmap='gray')\n",
    "axes[2].set_title('Sobel Y (Horizontal Edges)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building Basic CNN <a name=\"basic-cnn\"></a>\n",
    "\n",
    "Let's build a simple CNN for MNIST digit classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        \n",
    "        # Pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Conv1 + ReLU + Pool: 28x28 -> 14x14\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        \n",
    "        # Conv2 + ReLU + Pool: 14x14 -> 7x7\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        \n",
    "        # Conv3 + ReLU + Pool: 7x7 -> 3x3\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "        \n",
    "        # Flatten\n",
    "        x = x.view(-1, 128 * 3 * 3)\n",
    "        \n",
    "        # FC layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleCNN().to(device)\n",
    "print(model)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
    "\n",
    "# Training configuration\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_epoch(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in tqdm(loader, desc='Training'):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1)\n",
    "        correct += pred.eq(target).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = 100. * correct / len(loader.dataset)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "def test_epoch(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            total_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += pred.eq(target).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(loader)\n",
    "    accuracy = 100. * correct / len(loader.dataset)\n",
    "    return avg_loss, accuracy\n",
    "\n",
    "# Train for a few epochs (uncomment to run)\n",
    "# num_epochs = 5\n",
    "# for epoch in range(num_epochs):\n",
    "#     train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)\n",
    "#     test_loss, test_acc = test_epoch(model, test_loader, criterion)\n",
    "#     print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Train Acc={train_acc:.2f}%, \"\n",
    "#           f\"Test Loss={test_loss:.4f}, Test Acc={test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classic Architectures <a name=\"architectures\"></a>\n",
    "\n",
    "Let's implement some classic CNN architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet-5\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Residual Block for ResNet\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "# Simple ResNet\n",
    "class SimpleResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(SimpleResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.layer1 = ResidualBlock(64, 64)\n",
    "        self.layer2 = ResidualBlock(64, 128, stride=2)\n",
    "        self.layer3 = ResidualBlock(128, 256, stride=2)\n",
    "        \n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "# Test architectures\n",
    "lenet = LeNet5().to(device)\n",
    "resnet = SimpleResNet().to(device)\n",
    "\n",
    "print(\"LeNet-5 Parameters:\", sum(p.numel() for p in lenet.parameters()))\n",
    "print(\"Simple ResNet Parameters:\", sum(p.numel() for p in resnet.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Transfer Learning <a name=\"transfer\"></a>\n",
    "\n",
    "Using pre-trained models for new tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained ResNet18\n",
    "pretrained_model = models.resnet18(pretrained=True)\n",
    "\n",
    "# Freeze all layers\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final layer for our task\n",
    "num_features = pretrained_model.fc.in_features\n",
    "pretrained_model.fc = nn.Linear(num_features, 10)  # 10 classes for MNIST\n",
    "\n",
    "pretrained_model = pretrained_model.to(device)\n",
    "\n",
    "# Count trainable parameters\n",
    "trainable = sum(p.numel() for p in pretrained_model.parameters() if p.requires_grad)\n",
    "total = sum(p.numel() for p in pretrained_model.parameters())\n",
    "print(f\"Trainable parameters: {trainable:,} / {total:,}\")\n",
    "\n",
    "# Fine-tuning strategy\n",
    "def unfreeze_layers(model, num_layers=1):\n",
    "    \"\"\"Unfreeze the last num_layers for fine-tuning\"\"\"\n",
    "    layers = list(model.children())\n",
    "    for layer in layers[-num_layers:]:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "# Example: Unfreeze last 2 layers\n",
    "# unfreeze_layers(pretrained_model, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization <a name=\"visualization\"></a>\n",
    "\n",
    "Visualizing what CNNs learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_filters(model, layer_name='conv1'):\n",
    "    \"\"\"Visualize convolutional filters\"\"\"\n",
    "    layer = getattr(model, layer_name)\n",
    "    filters = layer.weight.data.cpu().numpy()\n",
    "    \n",
    "    n_filters = min(16, filters.shape[0])\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < n_filters:\n",
    "            # For single-channel filters\n",
    "            if filters.shape[1] == 1:\n",
    "                ax.imshow(filters[i, 0], cmap='gray')\n",
    "            else:\n",
    "                # For multi-channel, show first channel\n",
    "                ax.imshow(filters[i, 0], cmap='gray')\n",
    "            ax.set_title(f'Filter {i}')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Filters from {layer_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def visualize_feature_maps(model, image, layer_name='conv1'):\n",
    "    \"\"\"Visualize feature maps from a specific layer\"\"\"\n",
    "    activation = {}\n",
    "    \n",
    "    def hook(module, input, output):\n",
    "        activation['features'] = output\n",
    "    \n",
    "    # Register hook\n",
    "    layer = getattr(model, layer_name)\n",
    "    handle = layer.register_forward_hook(hook)\n",
    "    \n",
    "    # Forward pass\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        _ = model(image.unsqueeze(0).to(device))\n",
    "    \n",
    "    # Get activations\n",
    "    features = activation['features'].cpu().squeeze()\n",
    "    \n",
    "    # Visualize\n",
    "    n_features = min(16, features.shape[0])\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flatten()):\n",
    "        if i < n_features:\n",
    "            ax.imshow(features[i], cmap='viridis')\n",
    "            ax.set_title(f'Channel {i}')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'Feature Maps from {layer_name}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    handle.remove()\n",
    "\n",
    "# Visualize filters from our simple CNN\n",
    "# visualize_filters(model, 'conv1')\n",
    "\n",
    "# Visualize feature maps for a sample image\n",
    "# sample_image, _ = next(iter(test_loader))\n",
    "# visualize_feature_maps(model, sample_image[0], 'conv1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we covered:\n",
    "\n",
    "1. **Convolution Operations**: Understanding the fundamental building block\n",
    "2. **Basic CNN**: Building and training a simple CNN for MNIST\n",
    "3. **Classic Architectures**: LeNet-5 and ResNet implementations\n",
    "4. **Transfer Learning**: Using pre-trained models effectively\n",
    "5. **Visualization**: Understanding what CNNs learn\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Implement other architectures (VGG, Inception, EfficientNet)\n",
    "- Try advanced techniques (data augmentation, learning rate schedules)\n",
    "- Apply CNNs to different datasets (CIFAR-10, ImageNet)\n",
    "- Explore object detection (YOLO, Faster R-CNN)\n",
    "- Study semantic segmentation (U-Net, DeepLab)\n",
    "\n",
    "## Best Practices\n",
    "\n",
    "1. Start with pre-trained models when possible\n",
    "2. Use data augmentation for better generalization\n",
    "3. Apply batch normalization for stable training\n",
    "4. Use residual connections for very deep networks\n",
    "5. Monitor training with visualization and metrics\n",
    "6. Use appropriate regularization (dropout, weight decay)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
