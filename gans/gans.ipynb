{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative Adversarial Networks (GANs): Implementation Guide\n",
    "\n",
    "This notebook demonstrates GAN implementations from basic vanilla GANs to more advanced architectures.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Imports](#setup)\n",
    "2. [Vanilla GAN](#vanilla)\n",
    "3. [Deep Convolutional GAN (DCGAN)](#dcgan)\n",
    "4. [Training on MNIST](#mnist)\n",
    "5. [Conditional GAN](#conditional)\n",
    "6. [Evaluation and Visualization](#evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vanilla GAN <a name=\"vanilla\"></a>\n",
    "\n",
    "Let's start with a simple fully-connected GAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape):\n",
    "        super(Generator, self).__init__()\n",
    "        self.img_shape = img_shape\n",
    "        \n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        img = self.model(z)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_shape):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img):\n",
    "        img_flat = img.view(img.size(0), -1)\n",
    "        validity = self.model(img_flat)\n",
    "        return validity\n",
    "\n",
    "# Hyperparameters\n",
    "latent_dim = 100\n",
    "img_shape = (1, 28, 28)  # For MNIST\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator(latent_dim, img_shape).to(device)\n",
    "discriminator = Discriminator(img_shape).to(device)\n",
    "\n",
    "print(\"Generator architecture:\")\n",
    "print(generator)\n",
    "print(\"\\nDiscriminator architecture:\")\n",
    "print(discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Deep Convolutional GAN (DCGAN) <a name=\"dcgan\"></a>\n",
    "\n",
    "DCGAN uses convolutional layers for better image generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim, channels):\n",
    "        super(DCGenerator, self).__init__()\n",
    "        \n",
    "        self.init_size = 7  # Initial size before upsampling\n",
    "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
    "        \n",
    "        self.conv_blocks = nn.Sequential(\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64, 0.8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, z):\n",
    "        out = self.l1(z)\n",
    "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
    "        img = self.conv_blocks(out)\n",
    "        return img\n",
    "\n",
    "class DCDiscriminator(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(DCDiscriminator, self).__init__()\n",
    "        \n",
    "        def discriminator_block(in_filters, out_filters, bn=True):\n",
    "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1),\n",
    "                     nn.LeakyReLU(0.2, inplace=True),\n",
    "                     nn.Dropout2d(0.25)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
    "            return block\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_block(channels, 16, bn=False),\n",
    "            *discriminator_block(16, 32),\n",
    "            *discriminator_block(32, 64),\n",
    "            *discriminator_block(64, 128),\n",
    "        )\n",
    "        \n",
    "        # Calculate the size of the final feature map\n",
    "        ds_size = 28 // 2 ** 4\n",
    "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
    "    \n",
    "    def forward(self, img):\n",
    "        out = self.model(img)\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        validity = self.adv_layer(out)\n",
    "        return validity\n",
    "\n",
    "# Initialize DCGAN models\n",
    "dc_generator = DCGenerator(latent_dim, img_shape[0]).to(device)\n",
    "dc_discriminator = DCDiscriminator(img_shape[0]).to(device)\n",
    "\n",
    "print(\"DCGAN Generator:\")\n",
    "print(dc_generator)\n",
    "print(\"\\nDCGAN Discriminator:\")\n",
    "print(dc_discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training on MNIST <a name=\"mnist\"></a>\n",
    "\n",
    "Let's train our GAN on the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "dataloader = DataLoader(mnist, batch_size=64, shuffle=True)\n",
    "\n",
    "# Loss function and optimizers\n",
    "adversarial_loss = nn.BCELoss()\n",
    "\n",
    "optimizer_G = optim.Adam(dc_generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "optimizer_D = optim.Adam(dc_discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "# Training function\n",
    "def train_gan(generator, discriminator, dataloader, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (imgs, _) in enumerate(tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}')):\n",
    "            \n",
    "            # Adversarial ground truths\n",
    "            valid = torch.ones(imgs.size(0), 1).to(device)\n",
    "            fake = torch.zeros(imgs.size(0), 1).to(device)\n",
    "            \n",
    "            real_imgs = imgs.to(device)\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "            optimizer_G.zero_grad()\n",
    "            \n",
    "            # Sample noise as generator input\n",
    "            z = torch.randn(imgs.size(0), latent_dim).to(device)\n",
    "            \n",
    "            # Generate a batch of images\n",
    "            gen_imgs = generator(z)\n",
    "            \n",
    "            # Loss measures generator's ability to fool the discriminator\n",
    "            g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
    "            \n",
    "            g_loss.backward()\n",
    "            optimizer_G.step()\n",
    "            \n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            optimizer_D.zero_grad()\n",
    "            \n",
    "            # Measure discriminator's ability to classify real from generated samples\n",
    "            real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
    "            fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
    "            d_loss = (real_loss + fake_loss) / 2\n",
    "            \n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "        \n",
    "        print(f\"[Epoch {epoch+1}/{num_epochs}] [D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]\")\n",
    "        \n",
    "        # Save generated images every epoch\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            with torch.no_grad():\n",
    "                z = torch.randn(16, latent_dim).to(device)\n",
    "                gen_imgs = generator(z).cpu()\n",
    "                \n",
    "                fig, axes = plt.subplots(4, 4, figsize=(8, 8))\n",
    "                for idx, ax in enumerate(axes.flatten()):\n",
    "                    ax.imshow(gen_imgs[idx, 0], cmap='gray')\n",
    "                    ax.axis('off')\n",
    "                plt.suptitle(f'Generated Images - Epoch {epoch+1}')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "\n",
    "# Train the model (uncomment to run)\n",
    "# train_gan(dc_generator, dc_discriminator, dataloader, num_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conditional GAN <a name=\"conditional\"></a>\n",
    "\n",
    "Conditional GANs allow us to generate specific types of images by conditioning on labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalGenerator(nn.Module):\n",
    "    def __init__(self, latent_dim, num_classes, img_shape):\n",
    "        super(ConditionalGenerator, self).__init__()\n",
    "        self.img_shape = img_shape\n",
    "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
    "        \n",
    "        def block(in_feat, out_feat, normalize=True):\n",
    "            layers = [nn.Linear(in_feat, out_feat)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm1d(out_feat, 0.8))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *block(latent_dim + num_classes, 128, normalize=False),\n",
    "            *block(128, 256),\n",
    "            *block(256, 512),\n",
    "            *block(512, 1024),\n",
    "            nn.Linear(1024, int(np.prod(img_shape))),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, noise, labels):\n",
    "        # Concatenate label embedding and noise\n",
    "        gen_input = torch.cat((self.label_emb(labels), noise), -1)\n",
    "        img = self.model(gen_input)\n",
    "        img = img.view(img.size(0), *self.img_shape)\n",
    "        return img\n",
    "\n",
    "class ConditionalDiscriminator(nn.Module):\n",
    "    def __init__(self, num_classes, img_shape):\n",
    "        super(ConditionalDiscriminator, self).__init__()\n",
    "        self.label_embedding = nn.Embedding(num_classes, num_classes)\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(num_classes + int(np.prod(img_shape)), 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, img, labels):\n",
    "        # Concatenate label embedding and image\n",
    "        d_in = torch.cat((img.view(img.size(0), -1), self.label_embedding(labels)), -1)\n",
    "        validity = self.model(d_in)\n",
    "        return validity\n",
    "\n",
    "# Initialize conditional GAN\n",
    "num_classes = 10\n",
    "cond_generator = ConditionalGenerator(latent_dim, num_classes, img_shape).to(device)\n",
    "cond_discriminator = ConditionalDiscriminator(num_classes, img_shape).to(device)\n",
    "\n",
    "print(\"Conditional Generator initialized\")\n",
    "print(\"Conditional Discriminator initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluation and Visualization <a name=\"evaluation\"></a>\n",
    "\n",
    "Functions for evaluating and visualizing GAN outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_visualize(generator, num_samples=16, conditional=False, labels=None):\n",
    "    \"\"\"Generate and visualize samples from the generator\"\"\"\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(num_samples, latent_dim).to(device)\n",
    "        \n",
    "        if conditional and labels is not None:\n",
    "            labels_tensor = torch.LongTensor(labels).to(device)\n",
    "            gen_imgs = generator(z, labels_tensor).cpu()\n",
    "        else:\n",
    "            gen_imgs = generator(z).cpu()\n",
    "        \n",
    "        # Denormalize images\n",
    "        gen_imgs = (gen_imgs + 1) / 2\n",
    "        \n",
    "        # Plot\n",
    "        fig, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "        for idx, ax in enumerate(axes.flatten()):\n",
    "            ax.imshow(gen_imgs[idx, 0], cmap='gray')\n",
    "            if conditional and labels is not None:\n",
    "                ax.set_title(f'Label: {labels[idx]}')\n",
    "            ax.axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def interpolate_latent_space(generator, num_steps=10):\n",
    "    \"\"\"Visualize interpolation in latent space\"\"\"\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        # Generate two random points in latent space\n",
    "        z1 = torch.randn(1, latent_dim).to(device)\n",
    "        z2 = torch.randn(1, latent_dim).to(device)\n",
    "        \n",
    "        # Interpolate\n",
    "        alphas = np.linspace(0, 1, num_steps)\n",
    "        interpolated = []\n",
    "        \n",
    "        for alpha in alphas:\n",
    "            z = (1 - alpha) * z1 + alpha * z2\n",
    "            img = generator(z).cpu()\n",
    "            img = (img + 1) / 2\n",
    "            interpolated.append(img)\n",
    "        \n",
    "        # Plot\n",
    "        fig, axes = plt.subplots(1, num_steps, figsize=(20, 2))\n",
    "        for idx, ax in enumerate(axes):\n",
    "            ax.imshow(interpolated[idx][0, 0], cmap='gray')\n",
    "            ax.axis('off')\n",
    "        plt.suptitle('Latent Space Interpolation')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example usage (uncomment after training)\n",
    "# generate_and_visualize(dc_generator)\n",
    "# interpolate_latent_space(dc_generator)\n",
    "\n",
    "# For conditional GAN\n",
    "# labels = list(range(10)) + list(range(6))  # Generate digits 0-9 and 0-5\n",
    "# generate_and_visualize(cond_generator, conditional=True, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook, we covered:\n",
    "\n",
    "1. **Vanilla GAN**: Basic fully-connected architecture\n",
    "2. **DCGAN**: Convolutional architecture for better image generation\n",
    "3. **Training**: Complete training loop with visualization\n",
    "4. **Conditional GAN**: Generating specific classes of images\n",
    "5. **Evaluation**: Visualization and latent space interpolation\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "- Implement WGAN and WGAN-GP for more stable training\n",
    "- Try StyleGAN for high-quality image generation\n",
    "- Experiment with different datasets (CIFAR-10, CelebA)\n",
    "- Implement evaluation metrics (Inception Score, FID)\n",
    "- Explore image-to-image translation (Pix2Pix, CycleGAN)\n",
    "\n",
    "## Tips for Better Results\n",
    "\n",
    "1. Balance generator and discriminator training\n",
    "2. Use label smoothing for discriminator\n",
    "3. Add noise to discriminator inputs\n",
    "4. Monitor losses and generated samples regularly\n",
    "5. Experiment with different architectures and hyperparameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
